"""
å®è§‚æˆ˜æƒ…å®¤ V2 - èµ„é‡‘è½®åŠ¨ä¸ETFæ‰«ææ¨¡å—
åŒ…å«:
1. SOFR/Repoå†å²æ•°æ®è·å–
2. ETFæ¿å—èµ„é‡‘æµå…¥æ‰«æ
3. å¸‚åœºå¹¿åº¦é›·è¾¾å›¾æ•°æ®
4. èµ„é‡‘è½®åŠ¨è¶‹åŠ¿è¯„åˆ†
5. ç»¼åˆè¯„åˆ†ä»ªè¡¨ç›˜
"""
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import requests
import warnings
warnings.filterwarnings('ignore')

try:
    import yfinance as yf
except ImportError:
    yf = None

# ==================== SOFR/Repo æ•°æ®è·å– ====================

def get_sofr_repo_history(days=30):
    """
    è·å– SOFR å’Œ Repo åˆ©ç‡çš„å†å²æ•°æ®
    æ•°æ®æ¥æº: NY Fed API
    """
    result = {
        'dates': [],
        'sofr': [],
        'tgcr': [],  # Tri-Party General Collateral Rate
        'bgcr': [],  # Broad General Collateral Rate
        'spread': [],  # SOFR - TGCR
        'current_sofr': 4.33,
        'current_tgcr': 4.32,
        'current_spread': 0.01,
        'spread_alert': False,
        'spread_alert_msg': '',
        'success': False,
    }
    
    try:
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days + 15)  # å¤šå–ä¸€äº›ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
        
        # è·å– SOFR æ•°æ®
        sofr_url = f"https://markets.newyorkfed.org/api/rates/secured/sofr/search.json?startDate={start_date}&endDate={end_date}"
        r_sofr = requests.get(sofr_url, timeout=15)
        sofr_data = {}
        if r_sofr.status_code == 200:
            data = r_sofr.json()
            for item in data.get('refRates', []):
                date = item.get('effectiveDate', '')
                rate = item.get('percentRate', 0)
                sofr_data[date] = float(rate)
        
        # è·å– TGCR æ•°æ® (Tri-Party General Collateral Rate)
        tgcr_url = f"https://markets.newyorkfed.org/api/rates/secured/tgcr/search.json?startDate={start_date}&endDate={end_date}"
        r_tgcr = requests.get(tgcr_url, timeout=15)
        tgcr_data = {}
        if r_tgcr.status_code == 200:
            data = r_tgcr.json()
            for item in data.get('refRates', []):
                date = item.get('effectiveDate', '')
                rate = item.get('percentRate', 0)
                tgcr_data[date] = float(rate)
        
        # è·å– BGCR æ•°æ® (Broad General Collateral Rate)
        bgcr_url = f"https://markets.newyorkfed.org/api/rates/secured/bgcr/search.json?startDate={start_date}&endDate={end_date}"
        r_bgcr = requests.get(bgcr_url, timeout=15)
        bgcr_data = {}
        if r_bgcr.status_code == 200:
            data = r_bgcr.json()
            for item in data.get('refRates', []):
                date = item.get('effectiveDate', '')
                rate = item.get('percentRate', 0)
                bgcr_data[date] = float(rate)
        
        # åˆå¹¶æ•°æ® - å–å…±åŒæ—¥æœŸ
        common_dates = set(sofr_data.keys())
        if tgcr_data:
            common_dates = common_dates & set(tgcr_data.keys())
        all_dates = sorted(common_dates)[-days:]
        
        for date in all_dates:
            result['dates'].append(date)
            result['sofr'].append(sofr_data.get(date, 0))
            result['tgcr'].append(tgcr_data.get(date, 0))
            result['bgcr'].append(bgcr_data.get(date, 0))
            spread = sofr_data.get(date, 0) - tgcr_data.get(date, 0)
            result['spread'].append(spread)
        
        if result['sofr']:
            result['current_sofr'] = result['sofr'][-1]
            result['current_tgcr'] = result['tgcr'][-1] if result['tgcr'] else result['current_sofr']
            result['current_spread'] = result['spread'][-1] if result['spread'] else 0
            result['success'] = True
            
            # åˆ©å·®é¢„è­¦
            if result['current_spread'] > 0.10:
                result['spread_alert'] = True
                result['spread_alert_msg'] = f'ğŸš¨ æµåŠ¨æ€§ç´§ç¼º: SOFR-Repoåˆ©å·® {result["current_spread"]:.3f}% è¶…è¿‡è­¦æˆ’çº¿'
            elif result['current_spread'] > 0.05:
                result['spread_alert'] = True
                result['spread_alert_msg'] = f'âš ï¸ æµåŠ¨æ€§åç´§: SOFR-Repoåˆ©å·® {result["current_spread"]:.3f}%'
            else:
                result['spread_alert_msg'] = f'âœ… æµåŠ¨æ€§å……è£•: SOFR-Repoåˆ©å·® {result["current_spread"]:.3f}%'
                
    except Exception as e:
        print(f"SOFR/Repoæ•°æ®è·å–å¤±è´¥: {e}")
        result['spread_alert_msg'] = 'âš ï¸ SOFR/Repoæ•°æ®è·å–å¤±è´¥'
    
    return result


def get_rrp_tga_history(days=30):
    """
    è·å– RRP å’Œ TGA çš„å†å²æ•°æ®
    æ•°æ®æ¥æº: FRED
    """
    result = {
        'dates': [],
        'rrp': [],
        'tga': [],
        'net_drain': [],  # RRP + TGA åˆè®¡æŠ½æ°´
        'current_rrp': 0,
        'current_tga': 0,
        'rrp_chg_1d': 0,
        'tga_chg_1d': 0,
    }
    
    try:
        # RRP (Overnight Reverse Repo)
        rrp_url = "https://fred.stlouisfed.org/graph/fredgraph.csv?id=RRPONTSYD"
        rrp_df = pd.read_csv(rrp_url)
        
        # è‡ªåŠ¨æ£€æµ‹åˆ—å
        date_col = rrp_df.columns[0]
        rrp_col = 'RRPONTSYD' if 'RRPONTSYD' in rrp_df.columns else rrp_df.columns[1]
        
        rrp_df = rrp_df.dropna().tail(days + 5)
        rrp_df[date_col] = pd.to_datetime(rrp_df[date_col])
        
        # TGA (Treasury General Account) - å‘¨åº¦æ•°æ®
        tga_url = "https://fred.stlouisfed.org/graph/fredgraph.csv?id=WTREGEN"
        tga_df = pd.read_csv(tga_url)
        
        tga_date_col = tga_df.columns[0]
        tga_col = 'WTREGEN' if 'WTREGEN' in tga_df.columns else tga_df.columns[1]
        
        tga_df = tga_df.dropna().tail(days + 5)
        tga_df[tga_date_col] = pd.to_datetime(tga_df[tga_date_col])
        
        # å–æœ€è¿‘ days å¤©çš„ RRP æ•°æ®
        result['dates'] = rrp_df[date_col].dt.strftime('%Y-%m-%d').tolist()[-days:]
        result['rrp'] = rrp_df[rrp_col].tolist()[-days:]
        
        # TGA æ˜¯å‘¨åº¦æ•°æ®ï¼Œéœ€è¦å‰å‘å¡«å……å¯¹é½
        tga_dict = dict(zip(tga_df[tga_date_col].dt.strftime('%Y-%m-%d'), tga_df[tga_col]))
        result['tga'] = []
        last_tga = list(tga_dict.values())[-1] if tga_dict else 0
        for d in result['dates']:
            if d in tga_dict:
                last_tga = tga_dict[d]
            result['tga'].append(last_tga / 1000)  # è½¬æ¢ä¸ºåäº¿ç¾å…ƒ
        
        # è®¡ç®—å‡€æŠ½æ°´
        for i in range(len(result['dates'])):
            net = result['rrp'][i] + result['tga'][i] * 1000  # TGAå•ä½æ˜¯ç™¾ä¸‡
            result['net_drain'].append(net)
        
        if result['rrp']:
            result['current_rrp'] = result['rrp'][-1]
            result['rrp_chg_1d'] = result['rrp'][-1] - result['rrp'][-2] if len(result['rrp']) > 1 else 0
        if result['tga']:
            result['current_tga'] = result['tga'][-1]
            result['tga_chg_1d'] = result['tga'][-1] - result['tga'][-2] if len(result['tga']) > 1 else 0
            
    except Exception as e:
        print(f"RRP/TGAæ•°æ®è·å–å¤±è´¥: {e}")
    
    return result


# ==================== ETFæ¿å—èµ„é‡‘æµå…¥æ‰«æ ====================

# æ ¸å¿ƒæ¿å—ETFåˆ—è¡¨
SECTOR_ETFS = {
    # ç§‘æŠ€
    'XLK': ('ç§‘æŠ€', 'Technology'),
    'SMH': ('åŠå¯¼ä½“', 'Semiconductors'),
    'IGV': ('è½¯ä»¶', 'Software'),
    # é‡‘è
    'XLF': ('é‡‘è', 'Financials'),
    # èƒ½æº
    'XLE': ('èƒ½æº', 'Energy'),
    # åŒ»ç–—å¥åº·
    'XLV': ('åŒ»ç–—', 'Healthcare'),
    'XBI': ('ç”Ÿç‰©ç§‘æŠ€', 'Biotech'),
    # å·¥ä¸š
    'XLI': ('å·¥ä¸š', 'Industrials'),
    # æ¶ˆè´¹
    'XLY': ('å¯é€‰æ¶ˆè´¹', 'Consumer Discretionary'),
    'XLP': ('å¿…éœ€æ¶ˆè´¹', 'Consumer Staples'),
    # å…¬ç”¨äº‹ä¸š
    'XLU': ('å…¬ç”¨äº‹ä¸š', 'Utilities'),
    # æˆ¿åœ°äº§
    'XLRE': ('æˆ¿åœ°äº§', 'Real Estate'),
    # ææ–™
    'XLB': ('ææ–™', 'Materials'),
    # é€šä¿¡
    'XLC': ('é€šä¿¡æœåŠ¡', 'Communication'),
    # è§„æ¨¡å› å­
    'IWM': ('å°ç›˜è‚¡', 'Small Cap'),
    'QQQ': ('çº³æŒ‡100', 'Nasdaq 100'),
    'SPY': ('S&P500', 'S&P 500'),
    # é£æ ¼å› å­
    'IWF': ('æˆé•¿', 'Growth'),
    'IWD': ('ä»·å€¼', 'Value'),
}


def scan_etf_flows(yahoo_data=None, lookback=20):
    """
    æ‰«æETFèµ„é‡‘æµå…¥ä¿¡å·
    
    è¯„åˆ†æ ‡å‡† (0-5åˆ†):
    1. ä»·æ ¼ > SMA20 (+1)
    2. ä»·æ ¼ > SMA50 (+1)
    3. æˆäº¤é‡ > 20æ—¥å‡é‡ (+1) æˆ– åŠ¨é‡>0
    4. OBVä¸Šå‡ (+1)
    5. 20æ—¥æ¶¨å¹… > 0 (+1)
    
    è¿”å›: DataFrame with columns ['ETF', 'æ¿å—', 'ä»·æ ¼', '>SMA20', '>SMA50', 'æ”¾é‡', 'OBVâ†‘', '20æ—¥æ¶¨å¹…%', 'è¯„åˆ†']
    """
    results = []
    
    # å¦‚æœæ²¡æœ‰ä¼ å…¥æ•°æ®ï¼Œå°è¯•ç”¨yfinanceè·å–
    if yahoo_data is None or yahoo_data.empty:
        if yf is None:
            return pd.DataFrame()
        try:
            tickers = list(SECTOR_ETFS.keys())
            yahoo_data = yf.download(tickers, period='3mo', progress=False)
            if isinstance(yahoo_data.columns, pd.MultiIndex):
                yahoo_data = yahoo_data['Close']
        except Exception as e:
            print(f"ETFæ•°æ®è·å–å¤±è´¥: {e}")
            return pd.DataFrame()
    
    for ticker, (name_cn, name_en) in SECTOR_ETFS.items():
        if ticker not in yahoo_data.columns:
            continue
            
        try:
            prices = yahoo_data[ticker].dropna()
            if len(prices) < 50:
                continue
            
            # è®¡ç®—æŒ‡æ ‡
            sma20 = prices.rolling(20).mean()
            sma50 = prices.rolling(50).mean()
            
            latest = prices.iloc[-1]
            prev_20d = prices.iloc[-21] if len(prices) > 20 else prices.iloc[0]
            prev_5d = prices.iloc[-6] if len(prices) > 5 else prices.iloc[0]
            
            # è®¡ç®—OBV (ç®€åŒ–ç‰ˆï¼Œç”¨ä»·æ ¼å˜åŒ–æ–¹å‘)
            price_diff = prices.diff()
            obv_direction = (price_diff.iloc[-5:] > 0).sum() > 2.5  # è¿‘5å¤©å¤šæ•°ä¸Šæ¶¨
            
            # è¯„åˆ†
            score = 0
            signals = {}
            
            # 1. ä»·æ ¼ > SMA20
            above_sma20 = latest > sma20.iloc[-1]
            signals['>SMA20'] = 'âœ…' if above_sma20 else 'âŒ'
            if above_sma20:
                score += 1
            
            # 2. ä»·æ ¼ > SMA50
            above_sma50 = latest > sma50.iloc[-1] if not pd.isna(sma50.iloc[-1]) else False
            signals['>SMA50'] = 'âœ…' if above_sma50 else 'âŒ'
            if above_sma50:
                score += 1
            
            # 3. è¿‘æœŸåŠ¨é‡ (ç®€åŒ–: 5æ—¥æ¶¨å¹… > 0)
            mom_5d = (latest / prev_5d - 1) * 100
            signals['åŠ¨é‡'] = 'âœ…' if mom_5d > 0 else 'âŒ'
            if mom_5d > 0:
                score += 1
            
            # 4. OBVæ–¹å‘
            signals['OBVâ†‘'] = 'âœ…' if obv_direction else 'âŒ'
            if obv_direction:
                score += 1
            
            # 5. 20æ—¥æ¶¨å¹…
            returns_20d = (latest / prev_20d - 1) * 100
            if returns_20d > 0:
                score += 1
            
            # ä¿¡å·å¼ºåº¦
            if score >= 4:
                signal = 'ğŸŸ¢'
            elif score >= 3:
                signal = 'ğŸŸ¡'
            elif score <= 1:
                signal = 'ğŸ”´'
            else:
                signal = 'âšª'
            
            results.append({
                'ETF': ticker,
                'æ¿å—': name_cn,
                'ä¿¡å·': signal,
                'ä»·æ ¼': round(latest, 2),
                '>SMA20': signals['>SMA20'],
                '>SMA50': signals['>SMA50'],
                'åŠ¨é‡': signals['åŠ¨é‡'],
                'OBVâ†‘': signals['OBVâ†‘'],
                '20æ—¥%': round(returns_20d, 1),
                'è¯„åˆ†': score,
            })
            
        except Exception as e:
            print(f"ETF {ticker} æ‰«æå¤±è´¥: {e}")
            continue
    
    # æ’åº
    df = pd.DataFrame(results)
    if not df.empty:
        df = df.sort_values('è¯„åˆ†', ascending=False)
    
    return df


def get_etf_flow_summary(scan_results):
    """
    ç”ŸæˆETFèµ„é‡‘æµå‘æ‘˜è¦
    """
    if scan_results.empty:
        return {
            'strong_sectors': [],
            'weak_sectors': [],
            'neutral_sectors': [],
            'risk_on_score': 0,
            'summary': 'æ•°æ®ä¸è¶³',
        }
    
    strong = scan_results[scan_results['è¯„åˆ†'] >= 4]['æ¿å—'].tolist()
    weak = scan_results[scan_results['è¯„åˆ†'] <= 1]['æ¿å—'].tolist()
    neutral = scan_results[(scan_results['è¯„åˆ†'] > 1) & (scan_results['è¯„åˆ†'] < 4)]['æ¿å—'].tolist()
    
    # Risk-On è¯„åˆ†: å¼ºåŠ¿æ¿å—æ•° - å¼±åŠ¿æ¿å—æ•°
    risk_on_score = len(strong) - len(weak)
    
    # åˆ¤æ–­æ•´ä½“æƒ…ç»ª
    if risk_on_score > 3:
        summary = 'ğŸŸ¢ èµ„é‡‘ç§¯ææµå…¥é£é™©èµ„äº§'
    elif risk_on_score < -3:
        summary = 'ğŸ”´ èµ„é‡‘æ’¤ç¦»é£é™©èµ„äº§'
    else:
        summary = 'âšª èµ„é‡‘æµå‘åˆ†åŒ–'
    
    return {
        'strong_sectors': strong,
        'weak_sectors': weak,
        'neutral_sectors': neutral,
        'risk_on_score': risk_on_score,
        'summary': summary,
    }


# ==================== å¸‚åœºå¹¿åº¦é›·è¾¾å›¾æ•°æ® ====================

def calculate_breadth_radar(indicators, yahoo_data=None):
    """
    è®¡ç®—å¸‚åœºå¹¿åº¦é›·è¾¾å›¾æ•°æ®
    
    5ä¸ªç»´åº¦:
    1. æµåŠ¨æ€§ (å‡€æµåŠ¨æ€§Z-Score)
    2. é£é™©åå¥½ (HYG/LQD Z-Score)
    3. æ±‡ç‡ç¯å¢ƒ (DXYé€†å‘, å¼±ç¾å…ƒåˆ©å¥½)
    4. æ³¢åŠ¨ç‡ (VIXé€†å‘, ä½VIXåˆ©å¥½)
    5. å¸‚åœºå¹¿åº¦ (å°ç›˜/å¤§ç›˜ Z-Score)
    
    è¿”å›: dict with 'categories', 'values', 'normalized' (0-100 scale)
    """
    radar_data = {
        'categories': ['æµåŠ¨æ€§', 'é£é™©åå¥½', 'æ±‡ç‡ç¯å¢ƒ', 'æ³¢åŠ¨ç‡', 'å¸‚åœºå¹¿åº¦'],
        'values': [],
        'normalized': [],
        'signals': [],
        'raw_values': {},
    }
    
    def calc_zscore(series, window=60):
        if series is None or len(series) < window:
            return 0
        recent = series.iloc[-window:]
        mean = recent.mean()
        std = recent.std()
        if std == 0:
            return 0
        return (series.iloc[-1] - mean) / std
    
    # 1. æµåŠ¨æ€§ (å‡€æµåŠ¨æ€§Z-Score, æ­£å€¼åˆ©å¥½)
    liq = indicators.get('liquidity', {})
    net_liq = liq.get('net_liquidity', {})
    liq_z = net_liq.get('z_60d', 0) if net_liq else 0
    if pd.isna(liq_z):
        liq_z = 0
    radar_data['values'].append(liq_z)
    radar_data['normalized'].append(min(100, max(0, (liq_z + 3) / 6 * 100)))
    radar_data['signals'].append('ğŸŸ¢' if liq_z > 0.5 else 'ğŸ”´' if liq_z < -0.5 else 'âšª')
    radar_data['raw_values']['æµåŠ¨æ€§'] = {'z': liq_z, 'desc': 'å‡€æµåŠ¨æ€§'}
    
    # 2. é£é™©åå¥½ (HYG/LQD Z-Score, æ­£å€¼åˆ©å¥½)
    hyg_lqd = liq.get('hyg_lqd', {})
    risk_z = hyg_lqd.get('z_60d', 0) if hyg_lqd else 0
    if pd.isna(risk_z):
        risk_z = 0
    radar_data['values'].append(risk_z)
    radar_data['normalized'].append(min(100, max(0, (risk_z + 3) / 6 * 100)))
    radar_data['signals'].append('ğŸŸ¢' if risk_z > 0.5 else 'ğŸ”´' if risk_z < -0.5 else 'âšª')
    radar_data['raw_values']['é£é™©åå¥½'] = {'z': risk_z, 'desc': 'HYG/LQD'}
    
    # 3. æ±‡ç‡ç¯å¢ƒ (DXY Z-Score å–å, å¼±ç¾å…ƒåˆ©å¥½)
    curr = indicators.get('currency', {})
    dxy = curr.get('dxy', {})
    dxy_z = dxy.get('z_60d', 0) if dxy else 0
    if pd.isna(dxy_z):
        dxy_z = 0
    fx_z = -dxy_z  # å–å: å¼±ç¾å…ƒåˆ©å¥½
    radar_data['values'].append(fx_z)
    radar_data['normalized'].append(min(100, max(0, (fx_z + 3) / 6 * 100)))
    radar_data['signals'].append('ğŸŸ¢' if fx_z > 0.5 else 'ğŸ”´' if fx_z < -0.5 else 'âšª')
    radar_data['raw_values']['æ±‡ç‡ç¯å¢ƒ'] = {'z': fx_z, 'desc': 'DXYåå‘'}
    
    # 4. æ³¢åŠ¨ç‡ (VIX Z-Score å–å, ä½æ³¢åŠ¨åˆ©å¥½)
    vix = curr.get('vix', {})
    vix_z = vix.get('z_60d', 0) if vix else 0
    if pd.isna(vix_z):
        vix_z = 0
    vol_z = -vix_z  # å–å: ä½VIXåˆ©å¥½
    radar_data['values'].append(vol_z)
    radar_data['normalized'].append(min(100, max(0, (vol_z + 3) / 6 * 100)))
    radar_data['signals'].append('ğŸŸ¢' if vol_z > 0.5 else 'ğŸ”´' if vol_z < -0.5 else 'âšª')
    radar_data['raw_values']['æ³¢åŠ¨ç‡'] = {'z': vol_z, 'desc': 'VIXåå‘'}
    
    # 5. å¸‚åœºå¹¿åº¦ (å°ç›˜/å¤§ç›˜ Z-Score, æ­£å€¼è¡¨ç¤ºå°ç›˜è‚¡èµ°å¼º)
    us = indicators.get('us_structure', {})
    breadth_factors = us.get('breadth', [])
    breadth_z = 0
    for f in breadth_factors:
        if f.get('name') == 'å°ç›˜/å¤§ç›˜':
            breadth_z = f.get('z', 0)
            break
    if pd.isna(breadth_z):
        breadth_z = 0
    
    # å¦‚æœæ²¡æœ‰ä»indicatorsè·å–åˆ°ï¼Œå°è¯•ä»yahoo_dataè®¡ç®—
    if breadth_z == 0 and yahoo_data is not None:
        if 'IWM' in yahoo_data.columns and 'SPY' in yahoo_data.columns:
            iwm = yahoo_data['IWM'].dropna()
            spy = yahoo_data['SPY'].dropna()
            if len(iwm) > 60 and len(spy) > 60:
                ratio = iwm / spy
                ratio = ratio.dropna()
                if len(ratio) > 60:
                    breadth_z = calc_zscore(ratio, 60)
    
    radar_data['values'].append(breadth_z)
    radar_data['normalized'].append(min(100, max(0, (breadth_z + 3) / 6 * 100)))
    radar_data['signals'].append('ğŸŸ¢' if breadth_z > 0.5 else 'ğŸ”´' if breadth_z < -0.5 else 'âšª')
    radar_data['raw_values']['å¸‚åœºå¹¿åº¦'] = {'z': breadth_z, 'desc': 'IWM/SPY'}
    
    # è®¡ç®—ç»¼åˆè¯„åˆ† (å½’ä¸€åŒ–åˆ°0-100)
    avg_z = np.mean(radar_data['values'])
    radar_data['composite_score'] = min(100, max(0, (avg_z + 3) / 6 * 100))
    radar_data['composite_z'] = avg_z
    
    return radar_data


# ==================== èµ„é‡‘è½®åŠ¨è¶‹åŠ¿è¯„åˆ† ====================

def calculate_rotation_score(indicators, etf_scan_results=None):
    """
    è®¡ç®—èµ„é‡‘è½®åŠ¨è¶‹åŠ¿ç»¼åˆè¯„åˆ† (-100 åˆ° +100)
    
    è¯„åˆ†ç»´åº¦:
    1. é£é™©åå¥½å› å­ (35%)
    2. æ¿å—è½®åŠ¨å› å­ (40%)
    3. æµåŠ¨æ€§å¹¿åº¦å› å­ (25%)
    
    æ­£å€¼ = Risk-On (è¿›æ”»)
    è´Ÿå€¼ = Risk-Off (é˜²å¾¡)
    """
    score_components = {
        'risk_appetite': {'weight': 0.35, 'score': 0, 'factors': []},
        'sector_rotation': {'weight': 0.40, 'score': 0, 'factors': []},
        'liquidity_breadth': {'weight': 0.25, 'score': 0, 'factors': []},
    }
    
    us = indicators.get('us_structure', {})
    
    # 1. é£é™©åå¥½å› å­
    risk_factors = us.get('risk_appetite', [])
    if risk_factors:
        z_sum = sum(f.get('z', 0) for f in risk_factors if not pd.isna(f.get('z', 0)))
        avg_z = z_sum / len(risk_factors) if risk_factors else 0
        # è½¬æ¢ä¸º -100 åˆ° +100 (å‡è®¾Z-ScoreèŒƒå›´æ˜¯ -3 åˆ° +3)
        score_components['risk_appetite']['score'] = np.clip(avg_z / 3 * 100, -100, 100)
        score_components['risk_appetite']['factors'] = [
            {'name': f['name'], 'z': f.get('z', 0), 'signal': f.get('emoji', 'âšª')}
            for f in risk_factors
        ]
    
    # 2. æ¿å—è½®åŠ¨å› å­
    sector_factors = us.get('sector_rotation', [])
    if sector_factors:
        z_sum = sum(f.get('z', 0) for f in sector_factors if not pd.isna(f.get('z', 0)))
        avg_z = z_sum / len(sector_factors) if sector_factors else 0
        score_components['sector_rotation']['score'] = np.clip(avg_z / 3 * 100, -100, 100)
        score_components['sector_rotation']['factors'] = [
            {'name': f['name'], 'z': f.get('z', 0), 'signal': f.get('emoji', 'âšª')}
            for f in sector_factors
        ]
    
    # 3. æµåŠ¨æ€§å¹¿åº¦å› å­
    breadth_factors = us.get('breadth', [])
    if breadth_factors:
        z_sum = sum(f.get('z', 0) for f in breadth_factors if not pd.isna(f.get('z', 0)))
        avg_z = z_sum / len(breadth_factors) if breadth_factors else 0
        score_components['liquidity_breadth']['score'] = np.clip(avg_z / 3 * 100, -100, 100)
        score_components['liquidity_breadth']['factors'] = [
            {'name': f['name'], 'z': f.get('z', 0), 'signal': f.get('emoji', 'âšª')}
            for f in breadth_factors
        ]
    
    # åŠ å…¥ETFæ‰«æç»“æœ (å¦‚æœæœ‰)
    if etf_scan_results is not None and not etf_scan_results.empty:
        # è®¡ç®—å¼ºåŠ¿/å¼±åŠ¿æ¿å—æ¯”ä¾‹
        strong = len(etf_scan_results[etf_scan_results['è¯„åˆ†'] >= 4])
        weak = len(etf_scan_results[etf_scan_results['è¯„åˆ†'] <= 1])
        total = len(etf_scan_results)
        
        if total > 0:
            etf_score = ((strong - weak) / total) * 100
            # å¾®è°ƒæ¿å—è½®åŠ¨è¯„åˆ† (åŠ æƒå¹³å‡)
            old_score = score_components['sector_rotation']['score']
            score_components['sector_rotation']['score'] = old_score * 0.7 + etf_score * 0.3
    
    # ç»¼åˆè¯„åˆ†
    total_score = sum(
        comp['score'] * comp['weight']
        for comp in score_components.values()
    )
    
    # åˆ¤æ–­å¸‚åœºçŠ¶æ€
    if total_score > 60:
        market_state = 'ğŸš€ å¼ºåŠ›è¿›æ”» (Strong Risk-On)'
    elif total_score > 20:
        market_state = 'ğŸ“ˆ éœ‡è¡åå¤š (Mild Risk-On)'
    elif total_score > -20:
        market_state = 'âš–ï¸ æ— åºéœ‡è¡ (Neutral)'
    elif total_score > -60:
        market_state = 'ğŸ“‰ é¿é™©è°ƒæ•´ (Mild Risk-Off)'
    else:
        market_state = 'ğŸ”» ææ…ŒæŠ›å”® (Strong Risk-Off)'
    
    return {
        'total_score': np.clip(total_score, -100, 100),
        'market_state': market_state,
        'components': score_components,
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M'),
    }


# ==================== æµ‹è¯• ====================

if __name__ == '__main__':
    print("æµ‹è¯• SOFR/Repo æ•°æ®è·å–...")
    sofr_data = get_sofr_repo_history()
    print(f"  SOFR: {sofr_data['current_sofr']:.2f}%")
    print(f"  TGCR: {sofr_data['current_tgcr']:.2f}%")
    print(f"  åˆ©å·®: {sofr_data['current_spread']:.3f}%")
    print(f"  é¢„è­¦: {sofr_data['spread_alert_msg']}")
    
    print("\næµ‹è¯• RRP/TGA æ•°æ®è·å–...")
    rrp_tga = get_rrp_tga_history()
    print(f"  RRP: ${rrp_tga['current_rrp']:.0f}B")
    print(f"  TGA: ${rrp_tga['current_tga']:.0f}B")
